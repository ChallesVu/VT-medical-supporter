{"cells":[{"cell_type":"markdown","metadata":{},"source":["**TRAINING PART**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:07:58.898934Z","iopub.status.busy":"2024-05-14T10:07:58.898071Z","iopub.status.idle":"2024-05-14T10:07:58.903658Z","shell.execute_reply":"2024-05-14T10:07:58.902743Z","shell.execute_reply.started":"2024-05-14T10:07:58.898904Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","from datasets import load_dataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["*Prepare and process data*"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:07:58.906036Z","iopub.status.busy":"2024-05-14T10:07:58.905413Z","iopub.status.idle":"2024-05-14T10:07:58.918187Z","shell.execute_reply":"2024-05-14T10:07:58.917282Z","shell.execute_reply.started":"2024-05-14T10:07:58.906003Z"},"trusted":true},"outputs":[],"source":["def load_and_prepare_data(data):\n","    train_df, test_df = train_test_split(data, test_size=0.1)\n","    return train_df, test_df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:07:58.920893Z","iopub.status.busy":"2024-05-14T10:07:58.920084Z","iopub.status.idle":"2024-05-14T10:07:58.930809Z","shell.execute_reply":"2024-05-14T10:07:58.930098Z","shell.execute_reply.started":"2024-05-14T10:07:58.920862Z"},"trusted":true},"outputs":[],"source":["def preprocess_data(df, tokenizer):\n","    input_texts = [\"hỏi: \" + question for question in df['question']]\n","    target_texts = [\"trả lời: \" + answer for answer in df['answer']]\n","    model_inputs = tokenizer(input_texts, max_length=512, padding=\"max_length\", truncation=True)\n","\n","    # Prepare labels for the model\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(target_texts, max_length=128, padding=\"max_length\", truncation=True)[\"input_ids\"]\n","\n","    return {\n","        \"input_ids\": model_inputs[\"input_ids\"],\n","        \"attention_mask\": model_inputs[\"attention_mask\"],\n","        \"labels\": labels\n","    }"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:07:58.932279Z","iopub.status.busy":"2024-05-14T10:07:58.931805Z","iopub.status.idle":"2024-05-14T10:07:58.946073Z","shell.execute_reply":"2024-05-14T10:07:58.945332Z","shell.execute_reply.started":"2024-05-14T10:07:58.932256Z"},"trusted":true},"outputs":[],"source":["class MedicalQADataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.encodings['labels'][idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings['input_ids'])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T11:20:58.884161Z","iopub.status.busy":"2024-05-14T11:20:58.883817Z","iopub.status.idle":"2024-05-14T11:20:58.891275Z","shell.execute_reply":"2024-05-14T11:20:58.890228Z","shell.execute_reply.started":"2024-05-14T11:20:58.884137Z"},"trusted":true},"outputs":[],"source":["def train(model, train_dataset, device, optimizer, num_epochs=10):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        for batch in DataLoader(train_dataset, batch_size=8, shuffle=True):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            total_loss += loss.item()\n","        print(f\"Epoch {epoch+1}: Loss {total_loss / len(train_dataset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["*Hugging face data*"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["dataset = load_dataset(\"hungnm/vietnamese-medical-qa\")\n","data_hug = dataset['train'].to_pandas()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:07:58.959159Z","iopub.status.busy":"2024-05-14T10:07:58.958779Z","iopub.status.idle":"2024-05-14T10:08:01.433713Z","shell.execute_reply":"2024-05-14T10:08:01.432772Z","shell.execute_reply.started":"2024-05-14T10:07:58.959129Z"},"trusted":true},"outputs":[],"source":["train_df, test_df = load_and_prepare_data(data_hug)"]},{"cell_type":"markdown","metadata":{},"source":["*Crawled data*"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["file_path = 'edoctor_qna.csv'\n","crawled_data = pd.read_csv(file_path)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["crawled_train_df, crawled_test_df = load_and_prepare_data(crawled_data)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:08:01.435192Z","iopub.status.busy":"2024-05-14T10:08:01.434895Z","iopub.status.idle":"2024-05-14T10:08:01.440867Z","shell.execute_reply":"2024-05-14T10:08:01.439928Z","shell.execute_reply.started":"2024-05-14T10:08:01.435168Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:09:29.401536Z","iopub.status.busy":"2024-05-14T10:09:29.401163Z","iopub.status.idle":"2024-05-14T10:09:31.471731Z","shell.execute_reply":"2024-05-14T10:09:31.470752Z","shell.execute_reply.started":"2024-05-14T10:09:29.401506Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('model_medical_supporter.pth', map_location=torch.device('cpu')))"]},{"cell_type":"markdown","metadata":{},"source":["*Hugging face*"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:09:34.273997Z","iopub.status.busy":"2024-05-14T10:09:34.273624Z","iopub.status.idle":"2024-05-14T10:09:36.713214Z","shell.execute_reply":"2024-05-14T10:09:36.712417Z","shell.execute_reply.started":"2024-05-14T10:09:34.273968Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMINS\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["train_encoded = preprocess_data(train_df, tokenizer)\n","train_dataset = MedicalQADataset(train_encoded)"]},{"cell_type":"markdown","metadata":{},"source":["*Crawled data*"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["crawled_train_encoded = preprocess_data(crawled_train_df, tokenizer)\n","crawled_train_dataset = MedicalQADataset(crawled_train_encoded)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T10:09:40.715019Z","iopub.status.busy":"2024-05-14T10:09:40.714308Z","iopub.status.idle":"2024-05-14T10:09:40.962295Z","shell.execute_reply":"2024-05-14T10:09:40.961339Z","shell.execute_reply.started":"2024-05-14T10:09:40.714989Z"},"trusted":true},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"]},{"cell_type":"markdown","metadata":{},"source":["*Train with hugging face datasets*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T11:21:05.169558Z","iopub.status.busy":"2024-05-14T11:21:05.169225Z","iopub.status.idle":"2024-05-14T12:32:22.886341Z","shell.execute_reply":"2024-05-14T12:32:22.885359Z","shell.execute_reply.started":"2024-05-14T11:21:05.169534Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: Loss 0.18553266175062\n","Epoch 2: Loss 0.17358468127611096\n","Epoch 3: Loss 0.16251654106156482\n","Epoch 4: Loss 0.15156945305599398\n","Epoch 5: Loss 0.14128265080317445\n","Epoch 6: Loss 0.13153272425897092\n"]}],"source":["train(model, train_dataset, device, optimizer)"]},{"cell_type":"markdown","metadata":{},"source":["*Train with crawled datasets*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train(model, crawled_train_dataset, device, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:55:08.152701Z","iopub.status.busy":"2024-05-14T12:55:08.151414Z","iopub.status.idle":"2024-05-14T12:55:09.984981Z","shell.execute_reply":"2024-05-14T12:55:09.983953Z","shell.execute_reply.started":"2024-05-14T12:55:08.152653Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'model_medical_supporter.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:55:12.961536Z","iopub.status.busy":"2024-05-14T12:55:12.961167Z","iopub.status.idle":"2024-05-14T12:55:12.969810Z","shell.execute_reply":"2024-05-14T12:55:12.968929Z","shell.execute_reply.started":"2024-05-14T12:55:12.961509Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n"]},{"data":{"text/html":["<a href='medical_supporter.pth' target='_blank'>medical_supporter.pth</a><br>"],"text/plain":["/kaggle/working/medical_supporter.pth"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["%cd /kaggle/working\n","from IPython.display import FileLink\n","FileLink('model_medical_supporter.pth')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T11:16:00.354895Z","iopub.status.busy":"2024-05-14T11:16:00.354502Z","iopub.status.idle":"2024-05-14T11:16:00.361383Z","shell.execute_reply":"2024-05-14T11:16:00.360426Z","shell.execute_reply.started":"2024-05-14T11:16:00.354864Z"},"trusted":true},"outputs":[],"source":["def generate_answer(question, model, tokenizer, device):\n","    model.eval()\n","    input_text = \"hỏi: \" + question\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n","    input_ids = inputs.input_ids.to(device)\n","    attention_mask = inputs.attention_mask.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128, num_beams=4, early_stopping=True)\n","    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return answer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T12:54:32.396687Z","iopub.status.busy":"2024-05-14T12:54:32.395972Z","iopub.status.idle":"2024-05-14T12:54:34.196867Z","shell.execute_reply":"2024-05-14T12:54:34.195932Z","shell.execute_reply.started":"2024-05-14T12:54:32.396655Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Câu hỏi: Tôi tên là gì?\n","Câu trả lời: trả lời: Chào bạn! Xin được trả lời câu hỏi của bạn như sau, với những thông tin mà bạn cung cấp chưa đủ để bác sĩ có thể hỗ trợ tư vấn cho bạn như sau: Bạn có thể chat với bác sĩ edoctor để được hỗ trợ. Chúc bạn nhiều sức khỏe!\n"]}],"source":["question = \"Tôi tên là gì?\"\n","answer = generate_answer(question, model, tokenizer, device)\n","print(f\"Câu hỏi: {question}\")\n","print(f\"Câu trả lời: {answer}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Câu hỏi: Những triệu chứng của sùi mào gà?\n","Câu trả lời: trả lời: Chào bạn. Bệnh sùi mào gà ở nam là do virus Human papilloma gây nên và thường có thời gian ủ bệnh từ 1-3 tháng với các biểu hiện ban đầu là xuất hiện những u nhú nhỏ, hơi nhô cao trên bề mặt da, có hình tròn hoặc bầu dục, hơi nhô cao trên bề mặt da. Những u nhú này rất to và có kích thước không quá lớn, có màu hồng hoặc trắng đục, hơi nhô cao trên bề mặt da. Những u nhú này rất to và có kích thước không quá lớn, có hình dạng giống như mào gà hay súp lơ. Những u nhú này\n"]}],"source":["question = \"Những triệu chứng của sùi mào gà?\"\n","answer = generate_answer(question, model, tokenizer, device)\n","print(f\"Câu hỏi: {question}\")\n","print(f\"Câu trả lời: {answer}\")"]},{"cell_type":"markdown","metadata":{},"source":["**VALIDATION**"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Thưa bác sĩ. Em đi xét nghiệm máu, bác sĩ xác ...</td>\n","      <td>Chào bạn, có một số lý do vì sao bạn nhiễm HIV...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cho em hỏi. Năm nay em 18 rồi mà vẫn bị hẹp vớ...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Về việc hẹ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chào bác sĩ ! Tôi bị viêm dạ dày và trào ngược...</td>\n","      <td>Chào bạn, nếu bạn bị viêm dạ dày và trào ngược...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chào bác sĩ ! Cách đây 2 năm em có đi cắt bao ...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn về tình trạ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chào bác sĩ ! Em đã mổ nội soi đường tiết niệu...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Việc đi ti...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Bác sĩ cho em hỏi, em nay 16 tuổi, em hút thuố...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Cảm giác đ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Chào bác sĩ, em đang băn khoăn về việc dùng qu...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Đúng là th...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Chào bác sĩ, Bé nhà tôi 10 tuổi mới bị ngộ độc...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Khi bé bị ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Chào bác sĩ. Cho em xin tham khảo một số bệnh ...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Bé nhà bạn...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Chào bác sĩ ! Con em sinh ở Từ Dũ được hơn 2 n...</td>\n","      <td>Chào bạn, tôi hiểu lo lắng của bạn. Con bạn bị...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  Thưa bác sĩ. Em đi xét nghiệm máu, bác sĩ xác ...   \n","1  Cho em hỏi. Năm nay em 18 rồi mà vẫn bị hẹp vớ...   \n","2  Chào bác sĩ ! Tôi bị viêm dạ dày và trào ngược...   \n","3  Chào bác sĩ ! Cách đây 2 năm em có đi cắt bao ...   \n","4  Chào bác sĩ ! Em đã mổ nội soi đường tiết niệu...   \n","5  Bác sĩ cho em hỏi, em nay 16 tuổi, em hút thuố...   \n","6  Chào bác sĩ, em đang băn khoăn về việc dùng qu...   \n","7  Chào bác sĩ, Bé nhà tôi 10 tuổi mới bị ngộ độc...   \n","8  Chào bác sĩ. Cho em xin tham khảo một số bệnh ...   \n","9  Chào bác sĩ ! Con em sinh ở Từ Dũ được hơn 2 n...   \n","\n","                                              answer  \n","0  Chào bạn, có một số lý do vì sao bạn nhiễm HIV...  \n","1  Chào bạn, tôi hiểu lo lắng của bạn. Về việc hẹ...  \n","2  Chào bạn, nếu bạn bị viêm dạ dày và trào ngược...  \n","3  Chào bạn, tôi hiểu lo lắng của bạn về tình trạ...  \n","4  Chào bạn, tôi hiểu lo lắng của bạn. Việc đi ti...  \n","5  Chào bạn, tôi hiểu lo lắng của bạn. Cảm giác đ...  \n","6  Chào bạn, tôi hiểu lo lắng của bạn. Đúng là th...  \n","7  Chào bạn, tôi hiểu lo lắng của bạn. Khi bé bị ...  \n","8  Chào bạn, tôi hiểu lo lắng của bạn. Bé nhà bạn...  \n","9  Chào bạn, tôi hiểu lo lắng của bạn. Con bạn bị...  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["questions = []\n","answers = []\n","\n","file_path = 'validation_data.csv'\n","\n","with open(file_path, 'r', encoding='utf-8') as file:\n","    lines = file.readlines()\n","    for i in range(0, len(lines), 2):\n","        question = lines[i].strip()\n","        if i+1 < len(lines):\n","            answer = lines[i+1].strip()\n","        else:\n","            answer = ''\n","        questions.append(question)\n","        answers.append(answer)\n","\n","valid_df = pd.DataFrame({'question': questions, 'answer': answers})\n","valid_df.head(10)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["def evaluate(model, validation_dataset, device, tokenizer):\n","    model.eval()\n","    predictions, references = [], []\n","\n","    data_loader = DataLoader(validation_dataset, batch_size=8)\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n","            preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","            refs = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n","\n","            predictions.extend(preds)\n","            references.extend(refs)\n","\n","    return predictions, references"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMINS\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]}],"source":["valid_encoded = preprocess_data(valid_df, tokenizer)\n","validation_dataset = MedicalQADataset(valid_encoded)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["predictions, references = evaluate(model, validation_dataset, device, tokenizer)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from rouge_score import rouge_scorer"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ROUGE-1:  {'precision': 0.6187468492640995, 'recall': 0.6925914652570034, 'fmeasure': 0.629797814699461}\n","ROUGE-2:  {'precision': 0.2839473119811626, 'recall': 0.3168114291733257, 'fmeasure': 0.28808037531150577}\n","ROUGE-L:  {'precision': 0.37342785583944427, 'recall': 0.42003194353809503, 'fmeasure': 0.3803065644695269}\n"]}],"source":["# Compute ROUGE scores\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","rouge_scores = {\n","    'rouge1': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n","    'rouge2': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n","    'rougeL': {'precision': 0, 'recall': 0, 'fmeasure': 0},\n","}\n","\n","num_samples = len(predictions)\n","for pred, ref in zip(predictions, references):\n","    scores = scorer.score(ref, pred)\n","    for key in rouge_scores.keys():\n","        rouge_scores[key]['precision'] += scores[key].precision\n","        rouge_scores[key]['recall'] += scores[key].recall\n","        rouge_scores[key]['fmeasure'] += scores[key].fmeasure\n","\n","# Average the scores\n","for key in rouge_scores.keys():\n","    rouge_scores[key]['precision'] /= num_samples\n","    rouge_scores[key]['recall'] /= num_samples\n","    rouge_scores[key]['fmeasure'] /= num_samples\n","\n","# Print ROUGE scores\n","print(\"ROUGE-1: \", rouge_scores['rouge1'])\n","print(\"ROUGE-2: \", rouge_scores['rouge2'])\n","print(\"ROUGE-L: \", rouge_scores['rougeL'])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":4}
